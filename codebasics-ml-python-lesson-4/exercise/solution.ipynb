{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x: np.array, y: np.array):\n",
    "    m_curr = b_curr = 0\n",
    "    learning_rate = 0.0002\n",
    "    num_iterations = 100000\n",
    "    n = len(x)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        md = -(2 / n) * sum(x * (y - y_predicted))\n",
    "        bd = -(2 / n) * sum(y - y_predicted)\n",
    "        cost = (1 / n) * sum([val**2 for val in (y - y_predicted)])\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        print(\"m {}, b {}, iteration {}, cost {}\".format(m_curr, b_curr, i, cost))\n",
    "\n",
    "    return m_curr, b_curr, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>david</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laura</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanjay</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wei</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeff</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  math  cs\n",
       "0   david    92  98\n",
       "1   laura    56  68\n",
       "2  sanjay    88  81\n",
       "3     wei    70  80\n",
       "4    jeff    80  83"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"scores.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([92, 56, 88, 70, 80, 49, 65, 35, 66, 67]),\n",
       " array([98, 68, 81, 80, 83, 52, 66, 30, 68, 73]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(df[\"math\"])\n",
    "y = np.array(df[\"cs\"])\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 1.9783600000000003, b 0.027960000000000002, iteration 0, cost 5199.1\n",
      "m 0.20975041279999962, b 0.0030470367999999894, iteration 1, cost 4161.482445460163\n",
      "m 1.7908456142986242, b 0.025401286955264, iteration 2, cost 3332.2237319269248\n",
      "m 0.37738163667530467, b 0.005499731626422651, iteration 3, cost 2669.4843523161976\n",
      "m 1.6409848166378898, b 0.023373894401807944, iteration 4, cost 2139.826383775145\n",
      "m 0.5113514173939655, b 0.0074774305434828076, iteration 5, cost 1716.5264071567592\n",
      "m 1.5212165764726306, b 0.021771129698498662, iteration 6, cost 1378.2272007804495\n",
      "m 0.6184191426785134, b 0.009075514323270572, iteration 7, cost 1107.8601808918404\n",
      "m 1.4254981563597626, b 0.020507724625171385, iteration 8, cost 891.7842215178443\n",
      "m 0.7039868810749315, b 0.010370210797388455, iteration 9, cost 719.0974036421305\n",
      "m 1.3490002310389348, b 0.01951553325074733, iteration 10, cost 581.0869686205\n",
      "m 0.7723719384951477, b 0.01142244086408669, iteration 11, cost 470.7897237271261\n",
      "m 1.2878632281408475, b 0.018740093691150705, iteration 12, cost 382.6407204862143\n",
      "m 0.8270246840299113, b 0.012280892197750798, iteration 13, cost 312.1924801681589\n",
      "m 1.2390025969113474, b 0.01813788028359247, iteration 14, cost 255.89060022344475\n",
      "m 0.8707026352388424, b 0.012984475742007832, iteration 15, cost 210.89442007737276\n",
      "m 1.1999531799587442, b 0.01767410753812916, iteration 16, cost 174.93369813849728\n",
      "m 0.9056095862354473, b 0.013564288926616264, iteration 17, cost 146.19406878727372\n",
      "m 1.168744835939885, b 0.017320975066834464, iteration 18, cost 123.2255001796068\n",
      "m 0.9335067981503328, b 0.014045184660493999, iteration 19, cost 104.86913418555842\n",
      "m 1.1438030378387343, b 0.017056264940052912, iteration 20, cost 90.1988172376793\n",
      "m 0.9558018619881088, b 0.014447025263025912, iteration 21, cost 78.4743720801518\n",
      "m 1.123869431612398, b 0.016862220700598438, iteration 22, cost 69.10425278659366\n",
      "m 0.9736197173740411, b 0.014785684599634922, iteration 23, cost 61.61569883880534\n",
      "m 1.1079383470620547, b 0.016724651477560692, iteration 24, cost 55.63088241716976\n",
      "m 0.9878594103778675, b 0.015073848983471565, iteration 25, cost 50.84784543555072\n",
      "m 1.0952060576414993, b 0.016632215998581557, iteration 26, cost 47.02526451581355\n",
      "m 0.9992394540800741, b 0.015321657252001263, iteration 27, cost 43.970275232370476\n",
      "m 1.0850302291522722, b 0.01657585037608088, iteration 28, cost 41.528741309884765\n",
      "m 1.0083340805074807, b 0.015537212312981736, iteration 29, cost 39.57747781519814\n",
      "m 1.0768975113455124, b 0.01654831079689666, iteration 30, cost 38.01803597157669\n",
      "m 1.0156022129971571, b 0.01572698996942581, iteration 31, cost 36.77173601363096\n",
      "m 1.0703976372937574, b 0.016543808042154003, iteration 32, cost 35.775697470042715\n",
      "m 1.0214106207634122, b 0.015896165650447946, iteration 33, cost 34.97966658555935\n",
      "m 1.0652027237396349, b 0.016557715397389393, iteration 34, cost 34.34348081266759\n",
      "m 1.0260524239108442, b 0.016048875532907396, iteration 35, cost 33.83504244613808\n",
      "m 1.0610507280390304, b 0.01658633521579648, iteration 36, cost 33.42869916198312\n",
      "m 1.0297618825473565, b 0.016188425228507268, iteration 37, cost 33.103949752366304\n",
      "m 1.0577322270335765, b 0.0166267123567505, iteration 38, cost 32.84440975547639\n",
      "m 1.0327262161686235, b 0.016317456565470633, iteration 39, cost 32.63698479214377\n",
      "m 1.0550798507922887, b 0.016676485086818824, iteration 40, cost 32.47120990063734\n",
      "m 1.035095049650491, b 0.016438080879614143, iteration 41, cost 32.33872153636954\n",
      "m 1.052959838111218, b 0.01673376592060118, iteration 42, cost 32.23283559672576\n",
      "m 1.036987962438417, b 0.016551985539901195, iteration 43, cost 32.14821018063812\n",
      "m 1.0512652877114044, b 0.01679704638933073, iteration 44, cost 32.08057606773955\n",
      "m 1.0385005218215662, b 0.016660519083126275, iteration 45, cost 32.02652131866401\n",
      "m 1.0499107646303472, b 0.016865120932420777, iteration 46, cost 31.983319128693804\n",
      "m 1.0397091046950075, b 0.01676475925312493, iteration 47, cost 31.94879024926364\n",
      "m 1.0488279896772978, b 0.01693702607197308, iteration 48, cost 31.921193035921274\n",
      "m 1.0406747510877237, b 0.016865567377366896, iteration 49, cost 31.899135575212195\n",
      "m 1.047962394467687, b 0.017011991801351975, iteration 50, cost 31.881505456930224\n",
      "m 1.0414462438827428, b 0.016963631824454838, iteration 51, cost 31.86741364845402\n",
      "m 1.0472703682240316, b 0.01708940273517817, iteration 52, cost 31.85614963940047\n",
      "m 1.0420625701139212, b 0.017059502735137972, iteration 53, cost 31.847145593458148\n",
      "m 1.046717057433117, b 0.017168767060599943, iteration 54, cost 31.839947698713402\n",
      "m 1.0425548880219075, b 0.017153619779162816, iteration 55, cost 31.83419327097573\n",
      "m 1.0462746073431242, b 0.01724969172330578, iteration 56, cost 31.829592454870966\n",
      "m 1.0429480991153375, b 0.017246334338408182, iteration 57, cost 31.825913599447194\n",
      "m 1.0459207565770121, b 0.017331862596311, iteration 58, cost 31.82297157043309\n",
      "m 1.0432621045542085, b 0.017337927235534713, iteration 59, cost 31.82061840945363\n",
      "m 1.0456377139546258, b 0.017415028630952047, iteration 60, cost 31.81873586892226\n",
      "m 1.0435128092451273, b 0.017428622902632068, iteration 61, cost 31.81722944596486\n",
      "m 1.0454112608545958, b 0.01749898919044121, iteration 62, cost 31.816023614361388\n",
      "m 1.0437129243091645, b 0.017518600704730235, iteration 63, cost 31.81505801393808\n",
      "m 1.0452300338265001, b 0.017583583926907467, iteration 64, cost 31.81428440514876\n",
      "m 1.0438726084101126, b 0.01760800398949262, iteration 65, cost 31.81366423519171\n",
      "m 1.0450849512581242, b 0.017668684691178615, iteration 66, cost 31.813166692862268\n",
      "m 1.043999980300792, b 0.017696947319685068, iteration 67, cost 31.812767154001268\n",
      "m 1.0449687551708302, b 0.017754189067120032, iteration 68, cost 31.812445939105075\n",
      "m 1.0441015284474728, b 0.017785522253328603, iteration 69, cost 31.81218732041362\n",
      "m 1.0448756450247292, b 0.017840015204310798, iteration 70, cost 31.811978728380467\n",
      "m 1.0441824383996428, b 0.01787380196316831, iteration 71, cost 31.81181011748764\n",
      "m 1.0448009850576234, b 0.01792609768834459, iteration 72, cost 31.811673459407757\n",
      "m 1.0442468544222752, b 0.017961844928529556, iteration 73, cost 31.811562337942128\n",
      "m 1.0447410703917646, b 0.01801238424039495, iteration 74, cost 31.811471625297237\n",
      "m 1.0442980885910158, b 0.018049697885830843, iteration 75, cost 31.811397223366267\n",
      "m 1.044692940107559, b 0.01809883307952457, iteration 76, cost 31.811335856963026\n",
      "m 1.0443387879000003, b 0.018137398186618782, iteration 77, cost 31.811284908575193\n",
      "m 1.044654227853013, b 0.018185410814656123, iteration 78, cost 31.811242286300104\n",
      "m 1.04437106781358, b 0.01822497568209775, iteration 79, cost 31.811206318299767\n",
      "m 1.044623042451559, b 0.018272090759846052, iteration 80, cost 31.811175668449643\n",
      "m 1.0443966190001837, b 0.018312454229236455, iteration 81, cost 31.81114926892579\n",
      "m 1.044597872484431, b 0.018358851587859853, iteration 82, cost 31.81112626632863\n",
      "m 1.0444167926334849, b 0.018399852894440714, iteration 83, cost 31.811105978625633\n",
      "m 1.0445775100333783, b 0.018445676254116222, iteration 84, cost 31.811087860739732\n",
      "m 1.0444326685646632, b 0.01848718691552271, iteration 85, cost 31.81107147704813\n",
      "m 1.0445609897362342, b 0.0185325511367087, iteration 86, cost 31.81105647940329\n",
      "m 1.044445109805328, b 0.018574468470501836, iteration 87, cost 31.81104258956744\n",
      "m 1.044547540080427, b 0.01861946534911527, iteration 88, cost 31.811029585174346\n",
      "m 1.044454806070002, b 0.018661707292026614, iteration 89, cost 31.81101728851003\n",
      "m 1.0445365444770032, b 0.01870641019091935, iteration 90, cost 31.81100555754639\n",
      "m 1.0444623085750486, b 0.01874891115841746, iteration 91, cost 31.810994278775315\n",
      "m 1.0445275101511837, b 0.018793378708828794, iteration 92, cost 31.810983361481625\n",
      "m 1.0444680578498022, b 0.01883608628610563, iteration 93, cost 31.810972733166256\n",
      "m 1.044520043279852, b 0.018880365345844474, iteration 94, cost 31.810962335888206\n",
      "m 1.0444724059630832, b 0.01892323764326849, iteration 95, cost 31.810952123341476\n",
      "m 1.0445138291215608, b 0.0189673656608776, iteration 96, cost 31.810942058518464\n",
      "m 1.0444756342865145, b 0.01901036920048514, iteration 97, cost 31.810932111842874\n",
      "m 1.0445086161365338, b 0.01905437610466928, iteration 98, cost 31.81092225967744\n",
      "m 1.0444779676908766, b 0.01909748413105923, iteration 99, cost 31.81091248313143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0444779676908766, 0.01909748413105923, 31.81091248313143)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = gradient_descent(x, y)\n",
    "res\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edd9a7954580158322ea7bf85920c963e290ca3fe58e5e1d1fb8a6a450d93a23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
